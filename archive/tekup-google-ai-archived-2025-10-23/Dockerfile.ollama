FROM ollama/ollama:latest

# Install curl for health checks
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# Pre-download models during Docker build
# This makes startup faster in production
RUN ollama serve & \
    sleep 10 && \
    echo "Downloading llama3.1:8b model..." && \
    ollama pull llama3.1:8b && \
    echo "Downloading mistral:7b as fallback..." && \
    ollama pull mistral:7b && \
    echo "Models downloaded successfully!" && \
    pkill ollama

# Expose Ollama API port
EXPOSE 11434

# Health check - verifies Ollama is responding
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Start Ollama server
CMD ["ollama", "serve"]
