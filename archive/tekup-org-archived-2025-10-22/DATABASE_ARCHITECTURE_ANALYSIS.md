# üèóÔ∏è Database Arkitektur Analyse - Tekup.org

Som senior database udvikler har jeg identificeret kritiske problemer i jeres nuv√¶rende database arkitektur som kr√¶ver √∏jeblikkelig handling.

## üö® KRITISKE PROBLEMER

### 1. DATA FRAGMENTERING KRISE
**Problemet**: Multiple isolerede databaser med duplikerede, men inkonsistente entiteter

**Nuv√¶rende tilstand**:
```
üìä flow-api (PostgreSQL)     üìä crm-api (PostgreSQL)      üìä unified (SQLite)
‚îú‚îÄ‚îÄ Tenant (uuid, slug)      ‚îú‚îÄ‚îÄ Tenant (uuid, slug)       ‚îú‚îÄ‚îÄ Tenant (cuid, domain)
‚îú‚îÄ‚îÄ Lead (compliance)        ‚îú‚îÄ‚îÄ Lead (basic)              ‚îú‚îÄ‚îÄ Lead (consolidated)
‚îú‚îÄ‚îÄ ApiKey (hashed)          ‚îú‚îÄ‚îÄ ApiKey (hash)             ‚îî‚îÄ‚îÄ User (cuid)
‚îî‚îÄ‚îÄ SMS Tracking             ‚îî‚îÄ‚îÄ Deal Pipeline
```

**Konsekvenser**:
- üî¥ **Data Inconsistency**: Samme tenant forskellige IDs
- üî¥ **Impossible Cross-DB Joins**: Kan ikke lave rapporter p√• tv√¶rs  
- üî¥ **Duplikeret Business Logic**: Samme validering 3 steder
- üî¥ **Migration Nightmare**: Ingen sync mellem systemer

### 2. SCHEMA DIVERGENCE
**Lead Model Chaos**:

| Database | ID Type | Fields | Purpose |
|----------|---------|---------|---------|
| flow-api | UUID | 15+ compliance fields, JSON payload | Lead ingestion |
| crm-api | UUID | Basic tracking, conversion | Sales pipeline |
| unified | CUID | Consolidated attempt | ??? |

**Problemer**:
- Ingen f√¶lles Lead definition
- Umuligt at tracke lead journey
- Fragmenterede rapporter
- Duplikerede data

### 3. INDEXING DISASTERS

**flow-api**: Over-indexed (8+ indexes p√• Lead table)
```sql
@@index([tenantId, status, createdAt])      -- Compound index
@@index([tenantId, source, createdAt])      -- Overlapping  
@@index([tenantId, updatedAt])              -- Redundant
@@index([status])                           -- Low selectivity
@@index([source])                           -- Low selectivity  
@@index([createdAt])                        -- Time-series, OK
```

**Problemer**:
- üî¥ **Write Performance**: Hver INSERT opdaterer 8+ indexes
- üî¥ **Storage Waste**: Indexes kan v√¶re st√∏rre end data
- üî¥ **Maintenance Overhead**: VACUUM og ANALYZE tager lang tid

### 4. CONNECTION POOLING MANGEL

**Nuv√¶rende**:
```
App 1 ‚Üí PostgreSQL (flow-api)    [No pooling]
App 2 ‚Üí PostgreSQL (crm-api)     [No pooling]  
App 3 ‚Üí SQLite (unified)         [File locks]
```

**Risici**:
- üî¥ **Connection Exhaustion**: PostgreSQL max_connections = 100
- üî¥ **Performance Degradation**: New connection per request
- üî¥ **SQLite Locks**: Concurrent write conflicts

### 5. BACKUP & DISASTER RECOVERY

**Identificerede problems**:
- ‚ùå Ingen centraliseret backup strategi
- ‚ùå Ingen point-in-time recovery
- ‚ùå Ingen cross-region redundancy  
- ‚ùå SQLite backup strategy mangler
- ‚ùå Ingen automated testing af backups

## üí° L√òSNINGSFORSLAG

### üéØ FASE 1: DATABASE KONSOLIDERING (H√∏jeste prioritet)

**Target Architecture**:
```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ     TEKUP MASTER DATABASE       ‚îÇ
                    ‚îÇ        (PostgreSQL 16)          ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ               ‚îÇ               ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   TENANT DB    ‚îÇ ‚îÇAUDIT DB ‚îÇ ‚îÇ  CACHE DB   ‚îÇ
            ‚îÇ  (Multi-Schema)‚îÇ ‚îÇ (Logs)  ‚îÇ ‚îÇ  (Redis)    ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Schema konsolidering**:
```sql
-- Unified Tenant Model
CREATE SCHEMA core;
CREATE SCHEMA leads;
CREATE SCHEMA crm;
CREATE SCHEMA audit;

-- Master Tenant table
CREATE TABLE core.tenants (
    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    slug varchar(50) UNIQUE NOT NULL,
    domain varchar(255) UNIQUE NOT NULL,
    name varchar(255) NOT NULL,
    plan_type varchar(20) DEFAULT 'starter',
    settings jsonb DEFAULT '{}',
    active boolean DEFAULT true,
    created_at timestamptz DEFAULT now(),
    updated_at timestamptz DEFAULT now()
);

-- Unified Lead Model
CREATE TABLE leads.leads (
    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id uuid REFERENCES core.tenants(id),
    source varchar(50) NOT NULL,
    status lead_status DEFAULT 'new',
    contact_data jsonb NOT NULL, -- Structured contact info
    metadata jsonb DEFAULT '{}', -- Flexible additional data
    compliance_data jsonb DEFAULT '{}', -- Optional compliance fields
    scoring int DEFAULT 0,
    assigned_to uuid NULL,
    created_at timestamptz DEFAULT now(),
    updated_at timestamptz DEFAULT now()
);

-- Optimized indexes
CREATE INDEX CONCURRENTLY leads_tenant_status_created 
ON leads.leads(tenant_id, status, created_at) WHERE status != 'archived';

CREATE INDEX CONCURRENTLY leads_source_created 
ON leads.leads(tenant_id, source, created_at) WHERE created_at > now() - interval '1 year';
```

### üéØ FASE 2: CONNECTION POOLING & PERFORMANCE

**PgBouncer Setup**:
```ini
# pgbouncer.ini
[databases]
tekup = host=localhost port=5432 dbname=tekup_master

[pgbouncer]
pool_mode = transaction
max_client_conn = 100
default_pool_size = 25
min_pool_size = 5
max_db_connections = 50
```

**Application changes**:
```typescript
// Connection pool config
const pool = new Pool({
    host: 'localhost',
    port: 6432, // PgBouncer port
    database: 'tekup',
    min: 5,
    max: 25,
    acquireTimeoutMillis: 30000,
    idleTimeoutMillis: 30000
});
```

### üéØ FASE 3: MONITORING & OBSERVABILITY

**Prometheus + Grafana Dashboard**:
```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
  
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://monitor:password@postgres:5432/tekup?sslmode=disable
```

**Key metrics at overv√•ge**:
- Connection pool utilization
- Query execution time (p95, p99)
- Index hit ratio (should be > 99%)
- Transaction rate
- Lock wait time
- Disk I/O metrics

### üéØ FASE 4: BACKUP & DISASTER RECOVERY

**Automated backup strategy**:
```bash
#!/bin/bash
# backup-strategy.sh

# Point-in-time recovery setup
echo "archive_mode = on" >> postgresql.conf
echo "archive_command = 'cp %p /backup/archive/%f'" >> postgresql.conf

# Daily full backup
pg_basebackup -D /backup/full/$(date +%Y%m%d) -Ft -z -P

# WAL shipping til remote location
rsync -av /backup/archive/ backup-server:/backups/tekup/wal/

# Test restore procedure (automatiseret hver uge)
pg_restore --test /backup/full/$(date +%Y%m%d)/base.tar.gz
```

### üéØ FASE 5: DATA QUALITY & GOVERNANCE

**Data quality checks**:
```sql
-- Data quality constraints
ALTER TABLE leads.leads ADD CONSTRAINT valid_email 
CHECK (contact_data->>'email' ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' 
       OR contact_data->>'email' IS NULL);

ALTER TABLE leads.leads ADD CONSTRAINT valid_phone
CHECK (contact_data->>'phone' ~ '^\+?[1-9]\d{1,14}$' 
       OR contact_data->>'phone' IS NULL);

-- Audit trail
CREATE TABLE audit.data_changes (
    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    table_name varchar(50) NOT NULL,
    record_id uuid NOT NULL,
    operation varchar(10) NOT NULL, -- INSERT, UPDATE, DELETE
    old_values jsonb,
    new_values jsonb,
    user_id uuid,
    timestamp timestamptz DEFAULT now()
);
```

## üöÄ IMPLEMENTATION ROADMAP

### Week 1-2: Analysis & Planning
- [ ] Database migration scripts
- [ ] Data mapping mellem eksisterende schemas  
- [ ] Performance baseline measurements
- [ ] Backup af alle eksisterende data

### Week 3-4: Master Database Setup
- [ ] Setup PostgreSQL 16 med optimizations
- [ ] Create consolidated schema
- [ ] Setup PgBouncer
- [ ] Initial data migration (tenants f√∏rst)

### Week 5-6: Application Migration
- [ ] Update connection strings
- [ ] Deploy lead migration tools
- [ ] Gradual cutover per service
- [ ] Performance testing

### Week 7-8: Monitoring & Optimization  
- [ ] Deploy monitoring stack
- [ ] Setup alerting rules
- [ ] Query optimization baseret p√• real data
- [ ] Load testing

### Week 9-10: Backup & Security
- [ ] Automated backup system
- [ ] Disaster recovery testing
- [ ] Security audit
- [ ] Documentation

## üìä FORVENTET IMPACT

### Performance Improvements
- **Query Performance**: 3-5x hurtigere joins (no cross-DB)
- **Write Performance**: 2x improvement (fewer indexes)
- **Connection Efficiency**: 10x flere concurrent users
- **Storage Efficiency**: 40% mindre disk usage

### Operational Benefits  
- **Single source of truth** for all tenant data
- **Unified reporting** p√• tv√¶rs af alle moduler
- **Simplified deployment** - fewer databases
- **Better data consistency** og integrity
- **Centralized monitoring** og alerting

### Cost Savings
- **Infrastructure**: 60% f√¶rre database instances
- **Maintenance**: 70% mindre administrative overhead
- **Development**: 50% hurtigere feature development

## ‚ö†Ô∏è RISICI & MITIGATION

### Migration Risks
**Risk**: Data loss under migration
**Mitigation**: 
- Full backup f√∏r migration
- Parallel run periode
- Rollback plan dokumenteret

**Risk**: Downtime under migration  
**Mitigation**:
- Blue-green deployment
- Feature flags
- Graceful degradation

**Risk**: Performance regression
**Mitigation**:
- Extensive load testing
- Gradual rollout
- Performance monitoring fra dag 1

## üéØ NEXT ACTIONS

1. **Approved denne plan** med tech team
2. **Setup dedicated migration environment**
3. **Create detailed migration scripts**
4. **Schedule implementation phases**
5. **Setup monitoring f√∏r migration starts**

---

**Konklusion**: Jeres nuv√¶rende database arkitektur er ikke sustainable. Den foresl√•ede konsolidering vil l√∏se fundamentale problemer og give jer en robust foundation for fremtidig growth. 

**Timing**: Dette skal prioriteres h√∏jt - jo l√¶ngere I venter, jo mere kompleks bliver migrationen.
